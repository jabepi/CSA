I20241027 08:41:46.543666  9701 caffe.cpp:204] Using GPUs 0
I20241027 08:41:46.762012  9701 caffe.cpp:209] GPU 0: NVIDIA GeForce RTX 4090
I20241027 08:41:47.843097  9701 solver.cpp:45] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 100
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "examples/mnist/lenet_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I20241027 08:41:47.860626  9701 solver.cpp:102] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I20241027 08:41:47.863170  9701 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I20241027 08:41:47.863207  9701 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I20241027 08:41:47.863220  9701 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I20241027 08:41:47.863376  9701 layer_factory.hpp:77] Creating layer mnist
I20241027 08:41:47.917939  9701 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I20241027 08:41:47.919821  9701 net.cpp:86] Creating Layer mnist
I20241027 08:41:47.919896  9701 net.cpp:382] mnist -> data
I20241027 08:41:47.919986  9701 net.cpp:382] mnist -> label
I20241027 08:41:47.923069  9701 data_layer.cpp:45] output data size: 64,1,28,28
I20241027 08:41:47.924170  9701 net.cpp:124] Setting up mnist
I20241027 08:41:47.924225  9701 net.cpp:131] Top shape: 64 1 28 28 (50176)
I20241027 08:41:47.924265  9701 net.cpp:131] Top shape: 64 (64)
I20241027 08:41:47.924295  9701 net.cpp:139] Memory required for data: 200960
I20241027 08:41:47.924327  9701 layer_factory.hpp:77] Creating layer conv1
I20241027 08:41:47.924401  9701 net.cpp:86] Creating Layer conv1
I20241027 08:41:47.924436  9701 net.cpp:408] conv1 <- data
I20241027 08:41:47.924485  9701 net.cpp:382] conv1 -> conv1
I20241027 08:41:47.925417  9701 net.cpp:124] Setting up conv1
I20241027 08:41:47.925469  9701 net.cpp:131] Top shape: 64 20 24 24 (737280)
I20241027 08:41:47.925501  9701 net.cpp:139] Memory required for data: 3150080
I20241027 08:41:47.925570  9701 layer_factory.hpp:77] Creating layer pool1
I20241027 08:41:47.925673  9701 net.cpp:86] Creating Layer pool1
I20241027 08:41:47.925701  9701 net.cpp:408] pool1 <- conv1
I20241027 08:41:47.925734  9701 net.cpp:382] pool1 -> pool1
I20241027 08:41:47.925833  9701 net.cpp:124] Setting up pool1
I20241027 08:41:47.925863  9701 net.cpp:131] Top shape: 64 20 12 12 (184320)
I20241027 08:41:47.925892  9701 net.cpp:139] Memory required for data: 3887360
I20241027 08:41:47.925917  9701 layer_factory.hpp:77] Creating layer conv2
I20241027 08:41:47.925963  9701 net.cpp:86] Creating Layer conv2
I20241027 08:41:47.925988  9701 net.cpp:408] conv2 <- pool1
I20241027 08:41:47.926038  9701 net.cpp:382] conv2 -> conv2
I20241027 08:41:47.934257  9701 net.cpp:124] Setting up conv2
I20241027 08:41:47.934302  9701 net.cpp:131] Top shape: 64 50 8 8 (204800)
I20241027 08:41:47.934322  9701 net.cpp:139] Memory required for data: 4706560
I20241027 08:41:47.934341  9701 layer_factory.hpp:77] Creating layer pool2
I20241027 08:41:47.934367  9701 net.cpp:86] Creating Layer pool2
I20241027 08:41:47.934381  9701 net.cpp:408] pool2 <- conv2
I20241027 08:41:47.934396  9701 net.cpp:382] pool2 -> pool2
I20241027 08:41:47.934444  9701 net.cpp:124] Setting up pool2
I20241027 08:41:47.934458  9701 net.cpp:131] Top shape: 64 50 4 4 (51200)
I20241027 08:41:47.934470  9701 net.cpp:139] Memory required for data: 4911360
I20241027 08:41:47.934482  9701 layer_factory.hpp:77] Creating layer ip1
I20241027 08:41:47.934520  9701 net.cpp:86] Creating Layer ip1
I20241027 08:41:47.934531  9701 net.cpp:408] ip1 <- pool2
I20241027 08:41:47.934546  9701 net.cpp:382] ip1 -> ip1
I20241027 08:41:47.941663  9701 net.cpp:124] Setting up ip1
I20241027 08:41:47.941702  9701 net.cpp:131] Top shape: 64 500 (32000)
I20241027 08:41:47.941716  9701 net.cpp:139] Memory required for data: 5039360
I20241027 08:41:47.941736  9701 layer_factory.hpp:77] Creating layer relu1
I20241027 08:41:47.941756  9701 net.cpp:86] Creating Layer relu1
I20241027 08:41:47.941769  9701 net.cpp:408] relu1 <- ip1
I20241027 08:41:47.941783  9701 net.cpp:369] relu1 -> ip1 (in-place)
I20241027 08:41:47.941805  9701 net.cpp:124] Setting up relu1
I20241027 08:41:47.941817  9701 net.cpp:131] Top shape: 64 500 (32000)
I20241027 08:41:47.941829  9701 net.cpp:139] Memory required for data: 5167360
I20241027 08:41:47.941840  9701 layer_factory.hpp:77] Creating layer ip2
I20241027 08:41:47.941860  9701 net.cpp:86] Creating Layer ip2
I20241027 08:41:47.941872  9701 net.cpp:408] ip2 <- ip1
I20241027 08:41:47.941887  9701 net.cpp:382] ip2 -> ip2
I20241027 08:41:47.942087  9701 net.cpp:124] Setting up ip2
I20241027 08:41:47.942101  9701 net.cpp:131] Top shape: 64 10 (640)
I20241027 08:41:47.942113  9701 net.cpp:139] Memory required for data: 5169920
I20241027 08:41:47.942126  9701 layer_factory.hpp:77] Creating layer loss
I20241027 08:41:47.942145  9701 net.cpp:86] Creating Layer loss
I20241027 08:41:47.942157  9701 net.cpp:408] loss <- ip2
I20241027 08:41:47.942166  9701 net.cpp:408] loss <- label
I20241027 08:41:47.942176  9701 net.cpp:382] loss -> loss
I20241027 08:41:47.942193  9701 layer_factory.hpp:77] Creating layer loss
I20241027 08:41:47.942276  9701 net.cpp:124] Setting up loss
I20241027 08:41:47.942286  9701 net.cpp:131] Top shape: (1)
I20241027 08:41:47.942296  9701 net.cpp:134]     with loss weight 1
I20241027 08:41:47.942322  9701 net.cpp:139] Memory required for data: 5169924
I20241027 08:41:47.942330  9701 net.cpp:200] loss needs backward computation.
I20241027 08:41:47.942339  9701 net.cpp:200] ip2 needs backward computation.
I20241027 08:41:47.942348  9701 net.cpp:200] relu1 needs backward computation.
I20241027 08:41:47.942355  9701 net.cpp:200] ip1 needs backward computation.
I20241027 08:41:47.942364  9701 net.cpp:200] pool2 needs backward computation.
I20241027 08:41:47.942373  9701 net.cpp:200] conv2 needs backward computation.
I20241027 08:41:47.942381  9701 net.cpp:200] pool1 needs backward computation.
I20241027 08:41:47.942389  9701 net.cpp:200] conv1 needs backward computation.
I20241027 08:41:47.942425  9701 net.cpp:202] mnist does not need backward computation.
I20241027 08:41:47.942435  9701 net.cpp:244] This network produces output loss
I20241027 08:41:47.942449  9701 net.cpp:257] Network initialization done.
I20241027 08:41:47.943724  9701 solver.cpp:190] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I20241027 08:41:47.943776  9701 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I20241027 08:41:47.943794  9701 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I20241027 08:41:47.943982  9701 layer_factory.hpp:77] Creating layer mnist
I20241027 08:41:47.963161  9701 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I20241027 08:41:47.964745  9701 net.cpp:86] Creating Layer mnist
I20241027 08:41:47.964800  9701 net.cpp:382] mnist -> data
I20241027 08:41:47.964834  9701 net.cpp:382] mnist -> label
I20241027 08:41:47.965037  9701 data_layer.cpp:45] output data size: 100,1,28,28
I20241027 08:41:47.966434  9701 net.cpp:124] Setting up mnist
I20241027 08:41:47.966495  9701 net.cpp:131] Top shape: 100 1 28 28 (78400)
I20241027 08:41:47.966534  9701 net.cpp:131] Top shape: 100 (100)
I20241027 08:41:47.966562  9701 net.cpp:139] Memory required for data: 314000
I20241027 08:41:47.966590  9701 layer_factory.hpp:77] Creating layer label_mnist_1_split
I20241027 08:41:47.966629  9701 net.cpp:86] Creating Layer label_mnist_1_split
I20241027 08:41:47.966657  9701 net.cpp:408] label_mnist_1_split <- label
I20241027 08:41:47.966694  9701 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I20241027 08:41:47.966737  9701 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I20241027 08:41:47.967268  9701 net.cpp:124] Setting up label_mnist_1_split
I20241027 08:41:47.967319  9701 net.cpp:131] Top shape: 100 (100)
I20241027 08:41:47.967350  9701 net.cpp:131] Top shape: 100 (100)
I20241027 08:41:47.967379  9701 net.cpp:139] Memory required for data: 314800
I20241027 08:41:47.967428  9701 layer_factory.hpp:77] Creating layer conv1
I20241027 08:41:47.967517  9701 net.cpp:86] Creating Layer conv1
I20241027 08:41:47.967545  9701 net.cpp:408] conv1 <- data
I20241027 08:41:47.967579  9701 net.cpp:382] conv1 -> conv1
I20241027 08:41:47.968153  9701 net.cpp:124] Setting up conv1
I20241027 08:41:47.968184  9701 net.cpp:131] Top shape: 100 20 24 24 (1152000)
I20241027 08:41:47.968225  9701 net.cpp:139] Memory required for data: 4922800
I20241027 08:41:47.968264  9701 layer_factory.hpp:77] Creating layer pool1
I20241027 08:41:47.968295  9701 net.cpp:86] Creating Layer pool1
I20241027 08:41:47.968320  9701 net.cpp:408] pool1 <- conv1
I20241027 08:41:47.968350  9701 net.cpp:382] pool1 -> pool1
I20241027 08:41:47.968444  9701 net.cpp:124] Setting up pool1
I20241027 08:41:47.968472  9701 net.cpp:131] Top shape: 100 20 12 12 (288000)
I20241027 08:41:47.968501  9701 net.cpp:139] Memory required for data: 6074800
I20241027 08:41:47.968526  9701 layer_factory.hpp:77] Creating layer conv2
I20241027 08:41:47.968562  9701 net.cpp:86] Creating Layer conv2
I20241027 08:41:47.968587  9701 net.cpp:408] conv2 <- pool1
I20241027 08:41:47.968626  9701 net.cpp:382] conv2 -> conv2
I20241027 08:41:47.969920  9701 net.cpp:124] Setting up conv2
I20241027 08:41:47.969957  9701 net.cpp:131] Top shape: 100 50 8 8 (320000)
I20241027 08:41:47.969988  9701 net.cpp:139] Memory required for data: 7354800
I20241027 08:41:47.970043  9701 layer_factory.hpp:77] Creating layer pool2
I20241027 08:41:47.970077  9701 net.cpp:86] Creating Layer pool2
I20241027 08:41:47.970103  9701 net.cpp:408] pool2 <- conv2
I20241027 08:41:47.970146  9701 net.cpp:382] pool2 -> pool2
I20241027 08:41:47.970304  9701 net.cpp:124] Setting up pool2
I20241027 08:41:47.970340  9701 net.cpp:131] Top shape: 100 50 4 4 (80000)
I20241027 08:41:47.970377  9701 net.cpp:139] Memory required for data: 7674800
I20241027 08:41:47.970407  9701 layer_factory.hpp:77] Creating layer ip1
I20241027 08:41:47.970458  9701 net.cpp:86] Creating Layer ip1
I20241027 08:41:47.970486  9701 net.cpp:408] ip1 <- pool2
I20241027 08:41:47.970526  9701 net.cpp:382] ip1 -> ip1
I20241027 08:41:47.983093  9701 net.cpp:124] Setting up ip1
I20241027 08:41:47.983136  9701 net.cpp:131] Top shape: 100 500 (50000)
I20241027 08:41:47.983150  9701 net.cpp:139] Memory required for data: 7874800
I20241027 08:41:47.983166  9701 layer_factory.hpp:77] Creating layer relu1
I20241027 08:41:47.983184  9701 net.cpp:86] Creating Layer relu1
I20241027 08:41:47.983196  9701 net.cpp:408] relu1 <- ip1
I20241027 08:41:47.983208  9701 net.cpp:369] relu1 -> ip1 (in-place)
I20241027 08:41:47.983223  9701 net.cpp:124] Setting up relu1
I20241027 08:41:47.983233  9701 net.cpp:131] Top shape: 100 500 (50000)
I20241027 08:41:47.983243  9701 net.cpp:139] Memory required for data: 8074800
I20241027 08:41:47.983253  9701 layer_factory.hpp:77] Creating layer ip2
I20241027 08:41:47.983268  9701 net.cpp:86] Creating Layer ip2
I20241027 08:41:47.983276  9701 net.cpp:408] ip2 <- ip1
I20241027 08:41:47.983289  9701 net.cpp:382] ip2 -> ip2
I20241027 08:41:47.983461  9701 net.cpp:124] Setting up ip2
I20241027 08:41:47.983474  9701 net.cpp:131] Top shape: 100 10 (1000)
I20241027 08:41:47.983484  9701 net.cpp:139] Memory required for data: 8078800
I20241027 08:41:47.983496  9701 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I20241027 08:41:47.983511  9701 net.cpp:86] Creating Layer ip2_ip2_0_split
I20241027 08:41:47.983522  9701 net.cpp:408] ip2_ip2_0_split <- ip2
I20241027 08:41:47.983534  9701 net.cpp:382] ip2_ip2_0_split -> ip2_ip2_0_split_0
I20241027 08:41:47.983547  9701 net.cpp:382] ip2_ip2_0_split -> ip2_ip2_0_split_1
I20241027 08:41:47.983584  9701 net.cpp:124] Setting up ip2_ip2_0_split
I20241027 08:41:47.983594  9701 net.cpp:131] Top shape: 100 10 (1000)
I20241027 08:41:47.983604  9701 net.cpp:131] Top shape: 100 10 (1000)
I20241027 08:41:47.983614  9701 net.cpp:139] Memory required for data: 8086800
I20241027 08:41:47.983624  9701 layer_factory.hpp:77] Creating layer accuracy
I20241027 08:41:47.983646  9701 net.cpp:86] Creating Layer accuracy
I20241027 08:41:47.983677  9701 net.cpp:408] accuracy <- ip2_ip2_0_split_0
I20241027 08:41:47.983690  9701 net.cpp:408] accuracy <- label_mnist_1_split_0
I20241027 08:41:47.983701  9701 net.cpp:382] accuracy -> accuracy
I20241027 08:41:47.983717  9701 net.cpp:124] Setting up accuracy
I20241027 08:41:47.983727  9701 net.cpp:131] Top shape: (1)
I20241027 08:41:47.983737  9701 net.cpp:139] Memory required for data: 8086804
I20241027 08:41:47.983747  9701 layer_factory.hpp:77] Creating layer loss
I20241027 08:41:47.983759  9701 net.cpp:86] Creating Layer loss
I20241027 08:41:47.983769  9701 net.cpp:408] loss <- ip2_ip2_0_split_1
I20241027 08:41:47.983779  9701 net.cpp:408] loss <- label_mnist_1_split_1
I20241027 08:41:47.983791  9701 net.cpp:382] loss -> loss
I20241027 08:41:47.983805  9701 layer_factory.hpp:77] Creating layer loss
I20241027 08:41:47.983901  9701 net.cpp:124] Setting up loss
I20241027 08:41:47.983911  9701 net.cpp:131] Top shape: (1)
I20241027 08:41:47.983922  9701 net.cpp:134]     with loss weight 1
I20241027 08:41:47.983938  9701 net.cpp:139] Memory required for data: 8086808
I20241027 08:41:47.983948  9701 net.cpp:200] loss needs backward computation.
I20241027 08:41:47.983960  9701 net.cpp:202] accuracy does not need backward computation.
I20241027 08:41:47.983970  9701 net.cpp:200] ip2_ip2_0_split needs backward computation.
I20241027 08:41:47.983980  9701 net.cpp:200] ip2 needs backward computation.
I20241027 08:41:47.983990  9701 net.cpp:200] relu1 needs backward computation.
I20241027 08:41:47.984000  9701 net.cpp:200] ip1 needs backward computation.
I20241027 08:41:47.984017  9701 net.cpp:200] pool2 needs backward computation.
I20241027 08:41:47.984027  9701 net.cpp:200] conv2 needs backward computation.
I20241027 08:41:47.984038  9701 net.cpp:200] pool1 needs backward computation.
I20241027 08:41:47.984047  9701 net.cpp:200] conv1 needs backward computation.
I20241027 08:41:47.984058  9701 net.cpp:202] label_mnist_1_split does not need backward computation.
I20241027 08:41:47.984069  9701 net.cpp:202] mnist does not need backward computation.
I20241027 08:41:47.984078  9701 net.cpp:244] This network produces output accuracy
I20241027 08:41:47.984089  9701 net.cpp:244] This network produces output loss
I20241027 08:41:47.984113  9701 net.cpp:257] Network initialization done.
I20241027 08:41:47.984160  9701 solver.cpp:57] Solver scaffolding done.
I20241027 08:41:47.984467  9701 caffe.cpp:239] Starting Optimization
I20241027 08:41:47.984479  9701 solver.cpp:289] Solving LeNet
I20241027 08:41:47.984488  9701 solver.cpp:290] Learning Rate Policy: inv
I20241027 08:41:47.984925  9701 solver.cpp:347] Iteration 0, Testing net (#0)
I20241027 08:41:48.339371  9709 data_layer.cpp:73] Restarting data prefetching from start.
I20241027 08:41:48.352816  9701 solver.cpp:414]     Test net output #0: accuracy = 0.0776
I20241027 08:41:48.352856  9701 solver.cpp:414]     Test net output #1: loss = 2.36617 (* 1 = 2.36617 loss)
I20241027 08:41:48.359066  9701 solver.cpp:239] Iteration 0 (-1.35549e-17 iter/s, 0.374542s/100 iters), loss = 2.39189
I20241027 08:41:48.359107  9701 solver.cpp:258]     Train net output #0: loss = 2.39189 (* 1 = 2.39189 loss)
I20241027 08:41:48.359144  9701 sgd_solver.cpp:112] Iteration 0, lr = 0.01
I20241027 08:41:48.928181  9701 solver.cpp:464] Snapshotting to binary proto file examples/mnist/lenet_iter_100.caffemodel
I20241027 08:41:48.984577  9701 sgd_solver.cpp:284] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_100.solverstate
I20241027 08:41:49.043857  9701 solver.cpp:327] Iteration 100, loss = 0.243383
I20241027 08:41:49.043933  9701 solver.cpp:332] Optimization Done.
I20241027 08:41:49.043952  9701 caffe.cpp:250] Optimization Done.
I20241027 08:41:49.304503  9713 caffe.cpp:275] Use CPU.
I20241027 08:41:50.581139  9713 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I20241027 08:41:50.581208  9713 net.cpp:53] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I20241027 08:41:50.581413  9713 layer_factory.hpp:77] Creating layer mnist
I20241027 08:41:50.598969  9713 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I20241027 08:41:50.600363  9713 net.cpp:86] Creating Layer mnist
I20241027 08:41:50.600385  9713 net.cpp:382] mnist -> data
I20241027 08:41:50.600430  9713 net.cpp:382] mnist -> label
I20241027 08:41:50.600476  9713 data_layer.cpp:45] output data size: 100,1,28,28
I20241027 08:41:50.603185  9713 net.cpp:124] Setting up mnist
I20241027 08:41:50.603217  9713 net.cpp:131] Top shape: 100 1 28 28 (78400)
I20241027 08:41:50.603235  9713 net.cpp:131] Top shape: 100 (100)
I20241027 08:41:50.603248  9713 net.cpp:139] Memory required for data: 314000
I20241027 08:41:50.603264  9713 layer_factory.hpp:77] Creating layer label_mnist_1_split
I20241027 08:41:50.603282  9713 net.cpp:86] Creating Layer label_mnist_1_split
I20241027 08:41:50.603297  9713 net.cpp:408] label_mnist_1_split <- label
I20241027 08:41:50.603320  9713 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_0
I20241027 08:41:50.603341  9713 net.cpp:382] label_mnist_1_split -> label_mnist_1_split_1
I20241027 08:41:50.603371  9713 net.cpp:124] Setting up label_mnist_1_split
I20241027 08:41:50.603382  9713 net.cpp:131] Top shape: 100 (100)
I20241027 08:41:50.603394  9713 net.cpp:131] Top shape: 100 (100)
I20241027 08:41:50.603405  9713 net.cpp:139] Memory required for data: 314800
I20241027 08:41:50.603417  9713 layer_factory.hpp:77] Creating layer conv1
I20241027 08:41:50.603449  9713 net.cpp:86] Creating Layer conv1
I20241027 08:41:50.603461  9713 net.cpp:408] conv1 <- data
I20241027 08:41:50.603475  9713 net.cpp:382] conv1 -> conv1
I20241027 08:41:50.603564  9713 net.cpp:124] Setting up conv1
I20241027 08:41:50.603579  9713 net.cpp:131] Top shape: 100 20 24 24 (1152000)
I20241027 08:41:50.603637  9713 net.cpp:139] Memory required for data: 4922800
I20241027 08:41:50.603660  9713 layer_factory.hpp:77] Creating layer pool1
I20241027 08:41:50.603679  9713 net.cpp:86] Creating Layer pool1
I20241027 08:41:50.603700  9713 net.cpp:408] pool1 <- conv1
I20241027 08:41:50.603713  9713 net.cpp:382] pool1 -> pool1
I20241027 08:41:50.603735  9713 net.cpp:124] Setting up pool1
I20241027 08:41:50.603745  9713 net.cpp:131] Top shape: 100 20 12 12 (288000)
I20241027 08:41:50.603756  9713 net.cpp:139] Memory required for data: 6074800
I20241027 08:41:50.603767  9713 layer_factory.hpp:77] Creating layer conv2
I20241027 08:41:50.603787  9713 net.cpp:86] Creating Layer conv2
I20241027 08:41:50.603797  9713 net.cpp:408] conv2 <- pool1
I20241027 08:41:50.603811  9713 net.cpp:382] conv2 -> conv2
I20241027 08:41:50.604223  9713 net.cpp:124] Setting up conv2
I20241027 08:41:50.604235  9713 net.cpp:131] Top shape: 100 50 8 8 (320000)
I20241027 08:41:50.604246  9713 net.cpp:139] Memory required for data: 7354800
I20241027 08:41:50.604260  9713 layer_factory.hpp:77] Creating layer pool2
I20241027 08:41:50.604272  9713 net.cpp:86] Creating Layer pool2
I20241027 08:41:50.604281  9713 net.cpp:408] pool2 <- conv2
I20241027 08:41:50.604295  9713 net.cpp:382] pool2 -> pool2
I20241027 08:41:50.604311  9713 net.cpp:124] Setting up pool2
I20241027 08:41:50.604321  9713 net.cpp:131] Top shape: 100 50 4 4 (80000)
I20241027 08:41:50.604336  9713 net.cpp:139] Memory required for data: 7674800
I20241027 08:41:50.604346  9713 layer_factory.hpp:77] Creating layer ip1
I20241027 08:41:50.604365  9713 net.cpp:86] Creating Layer ip1
I20241027 08:41:50.604375  9713 net.cpp:408] ip1 <- pool2
I20241027 08:41:50.604386  9713 net.cpp:382] ip1 -> ip1
I20241027 08:41:50.610356  9713 net.cpp:124] Setting up ip1
I20241027 08:41:50.610384  9713 net.cpp:131] Top shape: 100 500 (50000)
I20241027 08:41:50.610392  9713 net.cpp:139] Memory required for data: 7874800
I20241027 08:41:50.610404  9713 layer_factory.hpp:77] Creating layer relu1
I20241027 08:41:50.610415  9713 net.cpp:86] Creating Layer relu1
I20241027 08:41:50.610422  9713 net.cpp:408] relu1 <- ip1
I20241027 08:41:50.610431  9713 net.cpp:369] relu1 -> ip1 (in-place)
I20241027 08:41:50.610445  9713 net.cpp:124] Setting up relu1
I20241027 08:41:50.610451  9713 net.cpp:131] Top shape: 100 500 (50000)
I20241027 08:41:50.610458  9713 net.cpp:139] Memory required for data: 8074800
I20241027 08:41:50.610464  9713 layer_factory.hpp:77] Creating layer ip2
I20241027 08:41:50.610476  9713 net.cpp:86] Creating Layer ip2
I20241027 08:41:50.610481  9713 net.cpp:408] ip2 <- ip1
I20241027 08:41:50.610491  9713 net.cpp:382] ip2 -> ip2
I20241027 08:41:50.610556  9713 net.cpp:124] Setting up ip2
I20241027 08:41:50.610563  9713 net.cpp:131] Top shape: 100 10 (1000)
I20241027 08:41:50.610570  9713 net.cpp:139] Memory required for data: 8078800
I20241027 08:41:50.610577  9713 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I20241027 08:41:50.610586  9713 net.cpp:86] Creating Layer ip2_ip2_0_split
I20241027 08:41:50.610594  9713 net.cpp:408] ip2_ip2_0_split <- ip2
I20241027 08:41:50.610601  9713 net.cpp:382] ip2_ip2_0_split -> ip2_ip2_0_split_0
I20241027 08:41:50.610610  9713 net.cpp:382] ip2_ip2_0_split -> ip2_ip2_0_split_1
I20241027 08:41:50.610620  9713 net.cpp:124] Setting up ip2_ip2_0_split
I20241027 08:41:50.610627  9713 net.cpp:131] Top shape: 100 10 (1000)
I20241027 08:41:50.610634  9713 net.cpp:131] Top shape: 100 10 (1000)
I20241027 08:41:50.610641  9713 net.cpp:139] Memory required for data: 8086800
I20241027 08:41:50.610647  9713 layer_factory.hpp:77] Creating layer accuracy
I20241027 08:41:50.610661  9713 net.cpp:86] Creating Layer accuracy
I20241027 08:41:50.610667  9713 net.cpp:408] accuracy <- ip2_ip2_0_split_0
I20241027 08:41:50.610674  9713 net.cpp:408] accuracy <- label_mnist_1_split_0
I20241027 08:41:50.610682  9713 net.cpp:382] accuracy -> accuracy
I20241027 08:41:50.610693  9713 net.cpp:124] Setting up accuracy
I20241027 08:41:50.610699  9713 net.cpp:131] Top shape: (1)
I20241027 08:41:50.610706  9713 net.cpp:139] Memory required for data: 8086804
I20241027 08:41:50.610734  9713 layer_factory.hpp:77] Creating layer loss
I20241027 08:41:50.610744  9713 net.cpp:86] Creating Layer loss
I20241027 08:41:50.610756  9713 net.cpp:408] loss <- ip2_ip2_0_split_1
I20241027 08:41:50.610764  9713 net.cpp:408] loss <- label_mnist_1_split_1
I20241027 08:41:50.610771  9713 net.cpp:382] loss -> loss
I20241027 08:41:50.610785  9713 layer_factory.hpp:77] Creating layer loss
I20241027 08:41:50.610811  9713 net.cpp:124] Setting up loss
I20241027 08:41:50.610818  9713 net.cpp:131] Top shape: (1)
I20241027 08:41:50.610826  9713 net.cpp:134]     with loss weight 1
I20241027 08:41:50.610847  9713 net.cpp:139] Memory required for data: 8086808
I20241027 08:41:50.610854  9713 net.cpp:200] loss needs backward computation.
I20241027 08:41:50.610862  9713 net.cpp:202] accuracy does not need backward computation.
I20241027 08:41:50.610869  9713 net.cpp:200] ip2_ip2_0_split needs backward computation.
I20241027 08:41:50.610877  9713 net.cpp:200] ip2 needs backward computation.
I20241027 08:41:50.610882  9713 net.cpp:200] relu1 needs backward computation.
I20241027 08:41:50.610889  9713 net.cpp:200] ip1 needs backward computation.
I20241027 08:41:50.610896  9713 net.cpp:200] pool2 needs backward computation.
I20241027 08:41:50.610903  9713 net.cpp:200] conv2 needs backward computation.
I20241027 08:41:50.610909  9713 net.cpp:200] pool1 needs backward computation.
I20241027 08:41:50.610916  9713 net.cpp:200] conv1 needs backward computation.
I20241027 08:41:50.610924  9713 net.cpp:202] label_mnist_1_split does not need backward computation.
I20241027 08:41:50.610930  9713 net.cpp:202] mnist does not need backward computation.
I20241027 08:41:50.610937  9713 net.cpp:244] This network produces output accuracy
I20241027 08:41:50.610944  9713 net.cpp:244] This network produces output loss
I20241027 08:41:50.610961  9713 net.cpp:257] Network initialization done.
I20241027 08:41:50.617101  9713 caffe.cpp:281] Running for 100 iterations.
I20241027 08:41:50.678516  9713 caffe.cpp:304] Batch 0, accuracy = 1
I20241027 08:41:50.678552  9713 caffe.cpp:304] Batch 0, loss = 0.0152328
I20241027 08:41:50.734180  9713 caffe.cpp:304] Batch 1, accuracy = 0.99
I20241027 08:41:50.734210  9713 caffe.cpp:304] Batch 1, loss = 0.0215251
I20241027 08:41:50.789675  9713 caffe.cpp:304] Batch 2, accuracy = 0.99
I20241027 08:41:50.789702  9713 caffe.cpp:304] Batch 2, loss = 0.0390841
I20241027 08:41:50.845197  9713 caffe.cpp:304] Batch 3, accuracy = 0.99
I20241027 08:41:50.845225  9713 caffe.cpp:304] Batch 3, loss = 0.026638
I20241027 08:41:50.900764  9713 caffe.cpp:304] Batch 4, accuracy = 0.99
I20241027 08:41:50.900789  9713 caffe.cpp:304] Batch 4, loss = 0.0307139
I20241027 08:41:50.956444  9713 caffe.cpp:304] Batch 5, accuracy = 0.99
I20241027 08:41:50.956471  9713 caffe.cpp:304] Batch 5, loss = 0.0495239
I20241027 08:41:51.011936  9713 caffe.cpp:304] Batch 6, accuracy = 0.98
I20241027 08:41:51.011965  9713 caffe.cpp:304] Batch 6, loss = 0.0581303
I20241027 08:41:51.069146  9713 caffe.cpp:304] Batch 7, accuracy = 1
I20241027 08:41:51.069175  9713 caffe.cpp:304] Batch 7, loss = 0.0139497
I20241027 08:41:51.124840  9713 caffe.cpp:304] Batch 8, accuracy = 1
I20241027 08:41:51.124867  9713 caffe.cpp:304] Batch 8, loss = 0.00961355
I20241027 08:41:51.180325  9713 caffe.cpp:304] Batch 9, accuracy = 0.99
I20241027 08:41:51.180349  9713 caffe.cpp:304] Batch 9, loss = 0.0243259
I20241027 08:41:51.235720  9713 caffe.cpp:304] Batch 10, accuracy = 0.98
I20241027 08:41:51.235747  9713 caffe.cpp:304] Batch 10, loss = 0.0589676
I20241027 08:41:51.291231  9713 caffe.cpp:304] Batch 11, accuracy = 0.98
I20241027 08:41:51.291258  9713 caffe.cpp:304] Batch 11, loss = 0.0329696
I20241027 08:41:51.346763  9713 caffe.cpp:304] Batch 12, accuracy = 0.95
I20241027 08:41:51.346791  9713 caffe.cpp:304] Batch 12, loss = 0.11429
I20241027 08:41:51.402186  9713 caffe.cpp:304] Batch 13, accuracy = 0.98
I20241027 08:41:51.402212  9713 caffe.cpp:304] Batch 13, loss = 0.0381607
I20241027 08:41:51.459318  9713 caffe.cpp:304] Batch 14, accuracy = 0.99
I20241027 08:41:51.459374  9713 caffe.cpp:304] Batch 14, loss = 0.039893
I20241027 08:41:51.515040  9713 caffe.cpp:304] Batch 15, accuracy = 0.98
I20241027 08:41:51.515079  9713 caffe.cpp:304] Batch 15, loss = 0.0532512
I20241027 08:41:51.570897  9713 caffe.cpp:304] Batch 16, accuracy = 0.98
I20241027 08:41:51.570930  9713 caffe.cpp:304] Batch 16, loss = 0.0305435
I20241027 08:41:51.626389  9713 caffe.cpp:304] Batch 17, accuracy = 0.99
I20241027 08:41:51.626418  9713 caffe.cpp:304] Batch 17, loss = 0.0272525
I20241027 08:41:51.681890  9713 caffe.cpp:304] Batch 18, accuracy = 0.99
I20241027 08:41:51.681916  9713 caffe.cpp:304] Batch 18, loss = 0.0227637
I20241027 08:41:51.737659  9713 caffe.cpp:304] Batch 19, accuracy = 0.98
I20241027 08:41:51.737687  9713 caffe.cpp:304] Batch 19, loss = 0.0433674
I20241027 08:41:51.796363  9713 caffe.cpp:304] Batch 20, accuracy = 0.99
I20241027 08:41:51.796396  9713 caffe.cpp:304] Batch 20, loss = 0.0700933
I20241027 08:41:51.853639  9713 caffe.cpp:304] Batch 21, accuracy = 0.98
I20241027 08:41:51.853668  9713 caffe.cpp:304] Batch 21, loss = 0.0695651
I20241027 08:41:51.909432  9713 caffe.cpp:304] Batch 22, accuracy = 0.99
I20241027 08:41:51.909458  9713 caffe.cpp:304] Batch 22, loss = 0.0329742
I20241027 08:41:51.965042  9713 caffe.cpp:304] Batch 23, accuracy = 1
I20241027 08:41:51.965068  9713 caffe.cpp:304] Batch 23, loss = 0.0129564
I20241027 08:41:52.020840  9713 caffe.cpp:304] Batch 24, accuracy = 0.98
I20241027 08:41:52.020869  9713 caffe.cpp:304] Batch 24, loss = 0.0402491
I20241027 08:41:52.076373  9713 caffe.cpp:304] Batch 25, accuracy = 0.99
I20241027 08:41:52.076401  9713 caffe.cpp:304] Batch 25, loss = 0.0914852
I20241027 08:41:52.132213  9713 caffe.cpp:304] Batch 26, accuracy = 0.99
I20241027 08:41:52.132241  9713 caffe.cpp:304] Batch 26, loss = 0.110783
I20241027 08:41:52.187943  9713 caffe.cpp:304] Batch 27, accuracy = 1
I20241027 08:41:52.188830  9713 caffe.cpp:304] Batch 27, loss = 0.0174422
I20241027 08:41:52.244405  9713 caffe.cpp:304] Batch 28, accuracy = 0.99
I20241027 08:41:52.244437  9713 caffe.cpp:304] Batch 28, loss = 0.0497742
I20241027 08:41:52.299849  9713 caffe.cpp:304] Batch 29, accuracy = 0.96
I20241027 08:41:52.299875  9713 caffe.cpp:304] Batch 29, loss = 0.115376
I20241027 08:41:52.355438  9713 caffe.cpp:304] Batch 30, accuracy = 0.99
I20241027 08:41:52.355466  9713 caffe.cpp:304] Batch 30, loss = 0.0228031
I20241027 08:41:52.410969  9713 caffe.cpp:304] Batch 31, accuracy = 1
I20241027 08:41:52.410996  9713 caffe.cpp:304] Batch 31, loss = 0.00311901
I20241027 08:41:52.466457  9713 caffe.cpp:304] Batch 32, accuracy = 0.99
I20241027 08:41:52.466485  9713 caffe.cpp:304] Batch 32, loss = 0.0210232
I20241027 08:41:52.522190  9713 caffe.cpp:304] Batch 33, accuracy = 1
I20241027 08:41:52.522219  9713 caffe.cpp:304] Batch 33, loss = 0.00607159
I20241027 08:41:52.578004  9713 caffe.cpp:304] Batch 34, accuracy = 0.99
I20241027 08:41:52.578040  9713 caffe.cpp:304] Batch 34, loss = 0.0526006
I20241027 08:41:52.634130  9713 caffe.cpp:304] Batch 35, accuracy = 0.95
I20241027 08:41:52.634160  9713 caffe.cpp:304] Batch 35, loss = 0.144204
I20241027 08:41:52.689617  9713 caffe.cpp:304] Batch 36, accuracy = 1
I20241027 08:41:52.689644  9713 caffe.cpp:304] Batch 36, loss = 0.00360956
I20241027 08:41:52.745168  9713 caffe.cpp:304] Batch 37, accuracy = 0.99
I20241027 08:41:52.745195  9713 caffe.cpp:304] Batch 37, loss = 0.0481802
I20241027 08:41:52.801065  9713 caffe.cpp:304] Batch 38, accuracy = 0.99
I20241027 08:41:52.801091  9713 caffe.cpp:304] Batch 38, loss = 0.033009
I20241027 08:41:52.856619  9713 caffe.cpp:304] Batch 39, accuracy = 0.98
I20241027 08:41:52.856647  9713 caffe.cpp:304] Batch 39, loss = 0.0381067
I20241027 08:41:52.912081  9713 caffe.cpp:304] Batch 40, accuracy = 1
I20241027 08:41:52.912107  9713 caffe.cpp:304] Batch 40, loss = 0.0168994
I20241027 08:41:52.967520  9713 caffe.cpp:304] Batch 41, accuracy = 0.99
I20241027 08:41:52.967545  9713 caffe.cpp:304] Batch 41, loss = 0.0646576
I20241027 08:41:53.023959  9713 caffe.cpp:304] Batch 42, accuracy = 0.98
I20241027 08:41:53.024022  9713 caffe.cpp:304] Batch 42, loss = 0.0393443
I20241027 08:41:53.082023  9713 caffe.cpp:304] Batch 43, accuracy = 0.99
I20241027 08:41:53.082058  9713 caffe.cpp:304] Batch 43, loss = 0.0119924
I20241027 08:41:53.137661  9713 caffe.cpp:304] Batch 44, accuracy = 0.99
I20241027 08:41:53.137688  9713 caffe.cpp:304] Batch 44, loss = 0.0186018
I20241027 08:41:53.193183  9713 caffe.cpp:304] Batch 45, accuracy = 0.99
I20241027 08:41:53.193208  9713 caffe.cpp:304] Batch 45, loss = 0.0206403
I20241027 08:41:53.248637  9713 caffe.cpp:304] Batch 46, accuracy = 0.99
I20241027 08:41:53.248663  9713 caffe.cpp:304] Batch 46, loss = 0.0163155
I20241027 08:41:53.304015  9713 caffe.cpp:304] Batch 47, accuracy = 1
I20241027 08:41:53.304041  9713 caffe.cpp:304] Batch 47, loss = 0.0079579
I20241027 08:41:53.359560  9713 caffe.cpp:304] Batch 48, accuracy = 0.96
I20241027 08:41:53.359586  9713 caffe.cpp:304] Batch 48, loss = 0.0654863
I20241027 08:41:53.415002  9713 caffe.cpp:304] Batch 49, accuracy = 1
I20241027 08:41:53.415033  9713 caffe.cpp:304] Batch 49, loss = 0.00345458
I20241027 08:41:53.454874  9713 caffe.cpp:304] Batch 50, accuracy = 1
I20241027 08:41:53.454892  9713 caffe.cpp:304] Batch 50, loss = 0.000160729
I20241027 08:41:53.494098  9713 caffe.cpp:304] Batch 51, accuracy = 1
I20241027 08:41:53.494114  9713 caffe.cpp:304] Batch 51, loss = 0.00479867
I20241027 08:41:53.533200  9713 caffe.cpp:304] Batch 52, accuracy = 1
I20241027 08:41:53.533214  9713 caffe.cpp:304] Batch 52, loss = 0.00408125
I20241027 08:41:53.572523  9713 caffe.cpp:304] Batch 53, accuracy = 1
I20241027 08:41:53.572538  9713 caffe.cpp:304] Batch 53, loss = 0.000900849
I20241027 08:41:53.612192  9713 caffe.cpp:304] Batch 54, accuracy = 1
I20241027 08:41:53.612208  9713 caffe.cpp:304] Batch 54, loss = 0.00317995
I20241027 08:41:53.651273  9713 caffe.cpp:304] Batch 55, accuracy = 1
I20241027 08:41:53.651284  9713 caffe.cpp:304] Batch 55, loss = 0.000586497
I20241027 08:41:53.699898  9713 caffe.cpp:304] Batch 56, accuracy = 1
I20241027 08:41:53.699926  9713 caffe.cpp:304] Batch 56, loss = 0.00467047
I20241027 08:41:53.742477  9713 caffe.cpp:304] Batch 57, accuracy = 1
I20241027 08:41:53.742491  9713 caffe.cpp:304] Batch 57, loss = 0.00521958
I20241027 08:41:53.781745  9713 caffe.cpp:304] Batch 58, accuracy = 1
I20241027 08:41:53.781759  9713 caffe.cpp:304] Batch 58, loss = 0.00477848
I20241027 08:41:53.820837  9713 caffe.cpp:304] Batch 59, accuracy = 0.98
I20241027 08:41:53.820850  9713 caffe.cpp:304] Batch 59, loss = 0.0742172
I20241027 08:41:53.859970  9713 caffe.cpp:304] Batch 60, accuracy = 1
I20241027 08:41:53.859984  9713 caffe.cpp:304] Batch 60, loss = 0.00446207
I20241027 08:41:53.899307  9713 caffe.cpp:304] Batch 61, accuracy = 1
I20241027 08:41:53.899320  9713 caffe.cpp:304] Batch 61, loss = 0.00500839
I20241027 08:41:53.938511  9713 caffe.cpp:304] Batch 62, accuracy = 1
I20241027 08:41:53.938524  9713 caffe.cpp:304] Batch 62, loss = 2.29745e-05
I20241027 08:41:53.977645  9713 caffe.cpp:304] Batch 63, accuracy = 1
I20241027 08:41:53.977658  9713 caffe.cpp:304] Batch 63, loss = 0.000104712
I20241027 08:41:54.016908  9713 caffe.cpp:304] Batch 64, accuracy = 1
I20241027 08:41:54.016922  9713 caffe.cpp:304] Batch 64, loss = 0.00059009
I20241027 08:41:54.056026  9713 caffe.cpp:304] Batch 65, accuracy = 0.94
I20241027 08:41:54.056039  9713 caffe.cpp:304] Batch 65, loss = 0.172991
I20241027 08:41:54.095016  9713 caffe.cpp:304] Batch 66, accuracy = 0.98
I20241027 08:41:54.095028  9713 caffe.cpp:304] Batch 66, loss = 0.0360228
I20241027 08:41:54.134243  9713 caffe.cpp:304] Batch 67, accuracy = 0.99
I20241027 08:41:54.134256  9713 caffe.cpp:304] Batch 67, loss = 0.0395608
I20241027 08:41:54.174413  9713 caffe.cpp:304] Batch 68, accuracy = 1
I20241027 08:41:54.174430  9713 caffe.cpp:304] Batch 68, loss = 0.00266908
I20241027 08:41:54.214557  9713 caffe.cpp:304] Batch 69, accuracy = 1
I20241027 08:41:54.214571  9713 caffe.cpp:304] Batch 69, loss = 0.000338747
I20241027 08:41:54.253676  9713 caffe.cpp:304] Batch 70, accuracy = 1
I20241027 08:41:54.253700  9713 caffe.cpp:304] Batch 70, loss = 0.00148271
I20241027 08:41:54.292829  9713 caffe.cpp:304] Batch 71, accuracy = 1
I20241027 08:41:54.292843  9713 caffe.cpp:304] Batch 71, loss = 0.000275629
I20241027 08:41:54.340240  9713 caffe.cpp:304] Batch 72, accuracy = 1
I20241027 08:41:54.340260  9713 caffe.cpp:304] Batch 72, loss = 0.00716042
I20241027 08:41:54.381418  9713 caffe.cpp:304] Batch 73, accuracy = 1
I20241027 08:41:54.381431  9713 caffe.cpp:304] Batch 73, loss = 9.70193e-05
I20241027 08:41:54.420431  9713 caffe.cpp:304] Batch 74, accuracy = 1
I20241027 08:41:54.420444  9713 caffe.cpp:304] Batch 74, loss = 0.00230344
I20241027 08:41:54.459546  9713 caffe.cpp:304] Batch 75, accuracy = 1
I20241027 08:41:54.459559  9713 caffe.cpp:304] Batch 75, loss = 0.000936681
I20241027 08:41:54.498855  9713 caffe.cpp:304] Batch 76, accuracy = 1
I20241027 08:41:54.498868  9713 caffe.cpp:304] Batch 76, loss = 0.000235471
I20241027 08:41:54.538079  9713 caffe.cpp:304] Batch 77, accuracy = 1
I20241027 08:41:54.538091  9713 caffe.cpp:304] Batch 77, loss = 0.000115684
I20241027 08:41:54.577500  9713 caffe.cpp:304] Batch 78, accuracy = 1
I20241027 08:41:54.577517  9713 caffe.cpp:304] Batch 78, loss = 0.00214567
I20241027 08:41:54.616729  9713 caffe.cpp:304] Batch 79, accuracy = 1
I20241027 08:41:54.616741  9713 caffe.cpp:304] Batch 79, loss = 0.00332435
I20241027 08:41:54.655839  9713 caffe.cpp:304] Batch 80, accuracy = 0.99
I20241027 08:41:54.655853  9713 caffe.cpp:304] Batch 80, loss = 0.018852
I20241027 08:41:54.695030  9713 caffe.cpp:304] Batch 81, accuracy = 1
I20241027 08:41:54.695042  9713 caffe.cpp:304] Batch 81, loss = 0.00106627
I20241027 08:41:54.734264  9713 caffe.cpp:304] Batch 82, accuracy = 1
I20241027 08:41:54.734277  9713 caffe.cpp:304] Batch 82, loss = 0.000892718
I20241027 08:41:54.773435  9713 caffe.cpp:304] Batch 83, accuracy = 1
I20241027 08:41:54.773448  9713 caffe.cpp:304] Batch 83, loss = 0.00885531
I20241027 08:41:54.812542  9713 caffe.cpp:304] Batch 84, accuracy = 0.99
I20241027 08:41:54.812556  9713 caffe.cpp:304] Batch 84, loss = 0.0244584
I20241027 08:41:54.852825  9713 caffe.cpp:304] Batch 85, accuracy = 0.99
I20241027 08:41:54.852839  9713 caffe.cpp:304] Batch 85, loss = 0.0282697
I20241027 08:41:54.892014  9713 caffe.cpp:304] Batch 86, accuracy = 1
I20241027 08:41:54.892025  9713 caffe.cpp:304] Batch 86, loss = 0.000129291
I20241027 08:41:54.931110  9713 caffe.cpp:304] Batch 87, accuracy = 1
I20241027 08:41:54.931123  9713 caffe.cpp:304] Batch 87, loss = 5.92891e-05
I20241027 08:41:54.970242  9713 caffe.cpp:304] Batch 88, accuracy = 1
I20241027 08:41:54.970253  9713 caffe.cpp:304] Batch 88, loss = 5.29461e-05
I20241027 08:41:55.010475  9713 caffe.cpp:304] Batch 89, accuracy = 1
I20241027 08:41:55.010488  9713 caffe.cpp:304] Batch 89, loss = 2.85956e-05
I20241027 08:41:55.049672  9713 caffe.cpp:304] Batch 90, accuracy = 0.97
I20241027 08:41:55.049685  9713 caffe.cpp:304] Batch 90, loss = 0.0901588
I20241027 08:41:55.088852  9713 caffe.cpp:304] Batch 91, accuracy = 1
I20241027 08:41:55.088865  9713 caffe.cpp:304] Batch 91, loss = 3.30768e-05
I20241027 08:41:55.127959  9713 caffe.cpp:304] Batch 92, accuracy = 1
I20241027 08:41:55.127972  9713 caffe.cpp:304] Batch 92, loss = 0.000576608
I20241027 08:41:55.167009  9713 caffe.cpp:304] Batch 93, accuracy = 1
I20241027 08:41:55.167021  9713 caffe.cpp:304] Batch 93, loss = 0.000542847
I20241027 08:41:55.206055  9713 caffe.cpp:304] Batch 94, accuracy = 1
I20241027 08:41:55.206068  9713 caffe.cpp:304] Batch 94, loss = 0.000424619
I20241027 08:41:55.245128  9713 caffe.cpp:304] Batch 95, accuracy = 1
I20241027 08:41:55.245141  9713 caffe.cpp:304] Batch 95, loss = 0.00775376
I20241027 08:41:55.245618  9720 data_layer.cpp:73] Restarting data prefetching from start.
I20241027 08:41:55.284238  9713 caffe.cpp:304] Batch 96, accuracy = 0.98
I20241027 08:41:55.284250  9713 caffe.cpp:304] Batch 96, loss = 0.0515422
I20241027 08:41:55.323753  9713 caffe.cpp:304] Batch 97, accuracy = 0.98
I20241027 08:41:55.323768  9713 caffe.cpp:304] Batch 97, loss = 0.0958139
I20241027 08:41:55.362623  9713 caffe.cpp:304] Batch 98, accuracy = 1
I20241027 08:41:55.362636  9713 caffe.cpp:304] Batch 98, loss = 0.00248095
I20241027 08:41:55.401746  9713 caffe.cpp:304] Batch 99, accuracy = 1
I20241027 08:41:55.401757  9713 caffe.cpp:304] Batch 99, loss = 0.00785476
I20241027 08:41:55.401762  9713 caffe.cpp:309] Loss: 0.0272126
I20241027 08:41:55.401767  9713 caffe.cpp:321] accuracy = 0.9915
I20241027 08:41:55.401775  9713 caffe.cpp:321] loss = 0.0272126 (* 1 = 0.0272126 loss)
